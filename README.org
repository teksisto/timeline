#+TITLE: Timeline
#+SETUPFILE: https://fniessen.github.io/org-html-themes/setup/theme-readtheorg.setup

[[./images/pepe_silvia.png]]

* Предпосылки

  Человеческая память ограничена. Поэтому нужен инструмент который
  помогает забывать лишнее, вспоминать нужное и наводить порядок в
  голове.

  Нет никакого решения для всех. Поэтому решением является инструмент
  для создания решений.

* Задачи инфоорга

  Сначала я выпишу задачи, которые решает любая система по хранению
  данных, чтобы потом можно было ссылаться на эти термины.

  Задачи инфоорга решаются последовательно. Если нет захвата, нечего
  идентифицировать. Если нет идентификации, не к чему привязывать
  классификацию.

  Каждый слой представляет абстракцию для других слоев.

  #+BEGIN_QUOTE
      И вот смотрю я на Singly и на предшествующий ему Memolane и до меня
      начинает доходить, что веб-сервисы еще не прошли тот этап, который
      для меня закончился — этап собирания разных данных в одно место. У
      меня были записи в разных форматах, в том числе несколько
      тетрадок. Тетрадки я оцифровал, форматы поубивал, заменив
      текстовыми файлами. Теперь у меня все лежит в одном месте в одном
      формате. Теперь все это можно как-то автоматически обрабатывать. В
      интернете этого еще не произошло, здесь все только начинается.
  #+END_QUOTE

** Захват

   Как данные попадают в систему?

   Захват – это больше про интерфейс.

   Keeping is not organizing.

   Захват должен сохранять контекст.

   Захват должен стоить 0. False positive keeping должен умереть. Если
   захват стоит ноль, значит сохранять надо все что почесало мозг. Мы
   не знаем зачем сохраняем.

   Компьютер знает о нас очень много. Все что может быть захвачено
   автоматически должно захватываться автоматически.

** Идентификация

   Как адресовать отдельный элемент в системе?

   Номеров страниц как в книгах больше нет, что делать?

   Идентификация отделяет слой классификации от слоя хранения. После
   того, как элемент добавлен в систему, ему пресваивается UUID и
   классификация осуществлется уже над UUID. Нельзя классифицировать
   прямые пути в файловую систему. Если файл перенести в другое
   место, метаданные, прикрепленные к этому файлу, будут ссылаться на
   пустое место.

   Системе должно быть безразлично не только что именно она
   описывает, но и где оно лежит. Хранение должно быть отделено от
   доступа.

   Есть необходимость идентифицировать не только отдельные документы,
   но и части этих документов.

** Хранение

   В каком формате хранить информацию из различных источников?

   Хочется унифицированности при которой не будет теряться информация.
   Например при переносе заметок из livejournal в wordpress может
   потеряться информация о текущей прослушиваемой музыке, которая есть
   в постах livejournal. Эта информация ничем особо не отличается ото
   всей остальной – просто метаданные для поста. Тем не менее она
   тереется, поскольку в целевой системе нет такого поля. Так
   вот. Данные должны забираться из источника целиком. Для этого нужна
   очень емкая структура для хранения. Подход сейчас я вижу только
   один - RDF.

** Классификация

   Как описывать объекты хранящиеся в системе?

   [[https://en.wikipedia.org/wiki/Ontology_(information_science)][Онтологии]].

   Не все файлы нуждаются в семантике. Целая куча постоянно
   скачивается, просматривается и удаляется. Нет никакого смысла
   наводить на них семантику, кроме может быть примитивной
   машинной. Те файлы, которые должны быть упорядочены, должны лежать
   в семантическом, тщательно структурируемом хранилище. Все
   остальное пускай лежит как раньше.

** Структурирование

   В какие структуры объединяются ресурсы?

   Группировка и сортировка.

   Структура информации являются функцией от ее объема. Как только
   меняется объем, структуре приходится его догонять. В одной папке с 10
   файлами легко найти нужный, в одной папке с 1000 файлами уже не
   очень. С другой стороны, если эта 1000 файлов отсортирована по какому-то
   признаку, там снова можно ориентироваться.

   Сохраненные запросы / Деревья / Контексты

** Поиск

   Как искать нужную информацию в массиве?

   #+BEGIN_QUOTE
       На больших объемах информации поиск итеративен и разные "мили"
       проходятся разными способами. Полнотекстовый поиск, сохраненные
       запросы и обычный иерархический подход будут мирно сосуществовать
       на машинах. (urbansheep)
   #+END_QUOTE

** Репрезентация

   Как отображать данные?

   Как нарисовать на экране все то, что у нас есть в базе.

** Аннотирование

   Как хранить и связывать аннотации с сохраненными ресурсами?

   Как аннотировать текст?

   Как аннотировать аудио-файлы?

   Как аннотировать видео?

   Аннотирование в самом простом случае – это комментирование.

   Как аннотировать обновляющийся источник? Обновляющийся источник
   сложно аннотировать. Какие-то части появляются, какие-то
   попадают. Последовательная нумерациия параграфов невозможна, потому
   что она будет ломаться каждую версию. Значит адресовать нужно по
   uuid.

   Удобство аннотирования – это аргумент в пользу блочной
   идентификации. Можно добавлять комментарии к каждому параграфу.

** Переносимость

   Есть ли импорт и экспорт из хранилища? Можно ли передвинуть данные
   куда-то еще?

   Я готов вбивать руками семантику на весь свой массив данных, но
   только при одном условии: чтобы мне больше никогда не приходилось
   это делать.

* Чего мне хочется от информационного менеджера

** Объединение базы данных и файлового менеджера

   Есть куча данных, которая не представлена файлами. Письма, записи
   из он-лайн сервисов, метрики. Для всего этого лучше подходит формат
   базы данных. В файловой системе хранение и классификация
   объединены. Если отделить хранение от классификации, то можно
   объединять в одну ленту как виртуальные сущности, которые лежат в
   БД, как и реальные файлы, представленные в общем-то теми же самыми
   записями в БД.

** Блочный текстовый редактор

   За неимением лучшего описания блочного текстового редактора сошлюсь
   пока на заметку Глеба Калинина [[http://glebkalinin.ru/content-management-vs-web-publishing/]["Контент-менеджмент и веб-публикации"]].

*** Зачем бить на блочные элементы

    Удобство идентификации – можно давать ссылку на конкретное место в
    тексте. Например цитаты – как пример производного ресурса – могут
    ссылаться на конкретное место, одкуда они были взяты. Возможность
    поставить ссылку на что угодно, начиная от параграфа и элемента
    списка до конкретной ячейки таблицы.

    Удобство классификации – можно навешивать атрибуты на что угодно.

    Удобство аннотирования – к каждому параграфу можно добавить
    аннотацию, например комментарий.

    Разбивка на параграфы позволяет строить параллельные тексты. Если
    параллелить две книги выглядит как сложная задача, то запараллелить
    несколько переводов стихотворения или две цитаты – это вполне
    посильная задача даже для выполнения руками.

    Разбивка на блочные элементы позволяет использовать разные движки
    для рендера. Например этот кусок написан textile'ом, тут нужна
    подсветка синтаксиса, а это описание графа на языке graphvis,
    которое нужно преобразовать картинку в.

** Динамические деревья

*** Проблемы иерархических файловых систем

   Главная проблема здесь в том, что хранение при таком подходе
   совмещено с классификацией.

   Обычные файловые системы устроены иерархически. В зависимости от
   схемы классификации файл можно положить в разные папки. Проблемы
   начинаются когда:

   - один и тот же файл можно положить в разные места.
   - изменился объем информации и схему надо детализировать
   - изменился подход и классификацию надо переделывать

   Структура – это функция от объема информации. Меняется объем –
   меняется структура.

*** Замена одного дерево на множество

   Предложение в том, чтобы отделить хранение от классификации и
   создавать множество разных деревьев на основе запросов.

   На что это похоже: примеры такого уже давно есть в нормальных
   музыкальных плеерах, которые предлагают разнообразные способы
   отображения коллекции.

   Запрос мог бы выглядеть следующим образом:
   - на первом уровне выбери все ресурсы с определенным типом и
     сгруппируй по значению атрибута
   - на втором уровне каждую из получившихся груп сгруппируй по
     значению другого атрибута
   - и т.д.

*** Сохранение файловой семантики

    Необходимо каким-то образом отображать динамическое дерево в
    файловую систему, чтобы все имеющиеся приложения могли работать со
    структурой папок, которая генерится запросом.


    Обычная проблема каталогизаторов, например calibre, в том, что
    доступ к структуре возможен только из интерфейса самого
    приложения. Нельзя пойти в папку, соответствующую
    ~категория/подкатегория/тег~ и открыть epub редактором.

**** FUSE

    Динамические деревья можно отобразить на файловую систему с
    помощью [[https://en.wikipedia.org/wiki/Virtual_file_system][виртуальной файловой системы]]. Под linux это [[https://en.wikipedia.org/wiki/Filesystem_in_Userspace][FUSE]].

    Биндинги для ruby: [[https://github.com/lwoggardner/rfusefs][rbusefs]]

    Пример использования: [[https://gist.github.com/teksisto/f35447da6e8079cfbe93][бесконечные рандомные pdf]]

**** WebDAV

    Либо, чтобы не связываться с системным программированием, можно
    использовать [[https://en.wikipedia.org/wiki/WebDAV][WebDAV]], монтировать веб-приложение как папку и снова
    пользоваться ей как файловой системой.

**** Hard links

    Либо это какой-то менеджер hard links. Под windows жесткие ссылки
    тоже есть, так что возможно это даже кросс-платформенное решение.

    Минус подхода в том, что он работает исключительно для реальных
    файлов, для виртуальных сущностей, типа записей в БД он не
    подходит.

** Контекст

   Контекст нужен для объединения ресурсов в одно целое и показывает
   хронологию развития какой-то темы. Контекст по природе
   гетерогенен. Он может захватывать ссылки, картинки, посты, ресурсы
   любого типа.

   Контекст – это легковестный блог с вики-страницей в заголовке.

   + Он предназначен либо для мелкого собирательства, которое возможно
     перерастет во что-то большее (например в заметку). Тогда заметка
     должна стать хедом.

   + Либо для подборки однотипных высказываний (рифмы из цитат). Хотя их можно
     делать и коммуникативными связями.

   + Крупномаштабный харвест всего встреченного на пути по интересной теме.

   На что это похоже:
   + tumbler – множество блогов у одного пользователя. Маленькие
     блоги на какую-нибудь обскурную тему, в которых есть два поста и
     новые появляются раз в год.
   + redmine – страница версии. Там в заголовке вики-страница, а в
     хвосте автоматичекий список задач из спринта, разбитых по типу
     работ.

   Атрибуты:

   - название
   - заголовочный блок
   - запрос, определяющий хвост
   - хвост = массив ресурсов

*** Заголовочный блок

    Заголовочный блок может использоваться как summary или описание
    того, зачем контекст нужен.

    Так же его можно использовать для агрегирования данных из
    элементов хвоста. Например контекст в который входят все
    поступления/расходы за месяц может показывать в заголовке график
    как менялась сумма денег в кошельке.

    Если контекст используется для создания категории постов, то есть
    как тег, то он дает некоторые преимущества. Маркер контекста может
    быть любым (хоть uuid). В то время как отображаться будет
    нормальное название. В головном блоке можно писать что здесь лежит
    и зачем.

*** Форма быстрого поста

   В контексте есть форма быстрого поста. Ты пишешь туда текст, а он
   сам разбирается какие атрибуты ему проставить. Интересный вопрос:
   как и чем из запроса можно выводить атрибуты, которые присущи новым
   записям.

*** Хвост

   Хвост определяется запросом.

   Контекст может захватывать ресурсы автоматически, если ему задать
   правила. Например все заметки, которые ссылаются на конкретного
   человека.

   Контекст умеет показывать хвост в прямом и обратном хронологическом
   порядках. Если я нахожу какой-то интересный блог в интернете, как
   правило мне хочется читать его с начала.

*** Контекст есть у каждого ресурса

    Еще одно странное следствие, это то, что контекст есть у каждого
    ресурса. То есть есть как минимум какой-то контекст по-умолчанию в
    который входят:

    - все ресурсы, которые ссылаются на данный
    - все ресурсы на которые ссылается он сам.

    Дело в том, что ни жесткое дерево, ни запутанный граф сами по себе
    не подходят для хранения. Часть данных всегда упорядочена, часть
    связей всегда нарушает иерархию. То есть получается дерево,
    опутанное дополнительными связями между узлами. Это всевозможный
    cross-referencing, ассоциативные связи и прочее случайное, что
    может объединять узлы. Тот контекст, который есть у каждого узла
    – это те самые случайные связи.

*** Контекст как строительный блок интерфейса

    Получается, что контекст – это один из основных строительных
    блоков интерфейса. Потому что любые коллекции (eg список
    полученных/отправленных писем для человека) – это фильтр, который
    вытаскивает сущности из базы и показывает в хедере статистику.

*** Динамическое дерево как вложенные контексты

    Интересно, что дерево вложенных контекстов – это и есть то самое
    динамическое дерево.

    Новые сущности просеиваются сначала сквозь фильтр первого
    контекста, потом через фильтры вложенных контекстов и где-то
    оседают. Механизм просеивания – это детали реализации.

    Еще раз. Контекст гетерогенен. Ему без разницы что засасывать,
    потому что засасывает он ресурсы, адресуемые uuid. Поэтому ничто
    не мешает ему содержать в себе другие контексты.

    В этом случае, кстати, голова контекста является элементом,
    отображаеммым в ленте контекста верхнего уровня. Не надо так же
    забывать, что голова контекста – это обычный ресурс и у него, как
    и у любого друго ресурса могут быть разные вьюшки для
    отображения. Что позволяет например ужать в графическом
    представлении весь контекст до заголовка со ссылкой.


** Параллельные тексты

   Под текстом здесь понимается любая информация, упорядоченная
   последовательно.

   Примеры параллельных текстов:

   - запись выступления и презентация
   - песня и ее текст
   - подкаст и трансрипт
   - фильм, аудио дорожки к нему и субтитры
   - цитата на двух языках
   - книга на двух языках

   Есть утилиты, которые строят параллельные тексты на разных языках
   автоматически. Например, параграф к параграфу. Как я предполагаю,
   они делают это на основе грубого машинного перевода и вычисления
   насколько параграфы идентичны.
   - [[http://www.abbyy.com/aligner/][Abbyy Aligner]]
   - [[http://www.supernova-soft.com/wpsite/products/text-aligner/create-parallel-text-for-language-lerning/][Supernova Aligner]]

   Ссылки:
   - [[https://en.wikipedia.org/wiki/Parallel_text][Parallel text]]
   - [[https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D1%82%D0%B5%D0%BA%D1%81%D1%82_(%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%B8%D0%BA%D0%B0_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)][Обучение через чтение параллельных текстов]]
   - [[http://ted.hyperland.com/myU/][Ted Nelson – My parallel universe]]

* Что бы я со всем этим делал
** Оглавления для источников

   В идеале книги должны импортироваться внутрь, биться на блочные
   элементы и цитаты должны привязываться непосредственно к тому
   пераграфу, откуда она была вытащена. Но это непростая операция,
   даже если на входе epub.

   Поэтому делается упрощенный вариант: от книги оставляется скелет
   в виде оглавления.

   Речь про то, что должен быть выбор: либо источник создается без
   оглавления, либо есть оглавление, либо полный импорт.

   Как достать оглавление:
   - [[https://stackoverflow.com/questions/2431426/extract-toc-of-pdf][PDF]] (=mutool show file.pdf outline=)
   - [[http://www.idpf.org/accessibility/guidelines/content/nav/toc.php][EPUB]] (здесь это xml-файл, лежащий в архиве)
   - FictionBook (опять xml)

** Конспекты
   Конспект точно так же привязывается к оглавлению, как и
   цитаты.

   В итоге к оглавлению привязываются: сам текст с возможностью
   комментирования любого параграфа и отсылками к заметкам, цитаты,
   новые слова, события, ссылки, карточки персоналий.

** Цитатник

*** Привязка цитат к оглавлению книги

    Цитаты привязываются к оглавлению источника.

*** Заголовки для цитат

    Простая фича, но мне ее не хватает (например в tumbler). Обычно я
    делаю заголовки в формате "#{автор} про #{тема}".

*** Форматирование внутри цитат

    Чтобы подсвечивать болдом/цветом куски текста и
    вставлять/сохранять ссылки.

    Паттерн "куда смотреть".

*** Параллельные цитатники

    Параллельные цитатники позволяют отображать версии одной и той же
    цитаты на разных языках. Напрмер чтобы сравнивать перевод и
    оригинал. Цитата по-прежнему является отдельной сущностью и
    крепится к оглавлению.

    [[https://htmlpreview.github.io/?https://github.com/teksisto/timeline/blob/doc/misc/parallel_quotes/quotes.html][Пример параллельного цитатника]] из книги Пирсига "Дзен и искусство
    ухода за мотоциклом". Поскольку не существует электронной версии
    перевода Горшкова я выписывал русские аналоги только для коротких
    цитат.

*** Колоды

    Колоды из цитат. Я называю это колодами, потому что когда-то
    печатал цитаты на карточках. Получалось что-то вроде карточной
    колоды. На самом деле это просто возможноть объединить
    произвольные цитаты в группу и добавить к ней описание.

*** Рифмы

    Если долго собирать цитаты между ними начинают проглядывать
    параллели. Есть мнение что люди часто говорят про одни и те же
    вещи, просто называют их по-разному. Хотелось бы помечать такие
    находки в цитатнике связями, а потом обсуждать и оценивать
    такие связи.

    Похожесть цитат не обязательно транизитивное свойство, но
    предполагаю, что для нескольких человек на относительно больших
    наборах цитат будут находится не только пары, но цепочки из цитат.

    #+BEGIN_QUOTE
        Reed College at that time offered perhaps the best calligraphy
        instruction in the country. Throughout the campus every poster,
        every label on every drawer, was beautifully hand
        calligraphed. Because I had dropped out and didn't have to take
        the normal classes, I decided to take a calligraphy class to learn
        how to do this. I learned about serif and san serif typefaces,
        about varying the amount of space between different letter
        combinations, about what makes great typography great. It was
        beautiful, historical, artistically subtle in a way that science
        can't capture, and I found it fascinating.

        None of this had even a hope of any practical application in my
        life. But ten years later, when we were designing the first Macintosh
        computer, it all came back to me. And we designed it all into the
        Mac. It was the first computer with beautiful typography. If I had
        never dropped in on that single course in college, the "Mac" would
        have never had multiple typefaces or proportionally spaced fonts. And
        since Windows just copied the Mac, it's likely that no personal
        computer would have them. If I had never dropped out, I would have
        never dropped in on that calligraphy class, and personal computers
        might not have the wonderful typography that they do. Of course it was
        impossible to connect the dots looking forward when I was in
        college. But it was very, very clear looking backwards 10 years later.
        Again, *you can't connect the dots looking forward*;
        you can only connect them looking backwards. So you have to trust that
        the dots will somehow connect in your future. You have to trust in
        something – your gut, destiny, life, karma, whatever – because
        believing that the dots will connect down the road will give you the
        confidence to follow your heart, even when it leads you off the
        well-worn path, and that will make all the difference.

        (Steve Jobs, [[http://www.americanrhetoric.com/speeches/stevejobsstanfordcommencement.htm][Commencement Address at Stanford University]])
    #+END_QUOTE

    #+BEGIN_QUOTE
        What you’re supposed to do in most freshman-rhetoric courses is to
        read a little essay or short story, discuss how the writer has done
        certain little things to achieve certain little effects, and then have
        the students write an imitative little essay or short story to see if
        they can do the same little things. He tried this over and over again
        but it never jelled. The students seldom achieved anything, as a
        result of this calculated mimicry, that was remotely close to the
        models he’d given them. More often their writing got worse. It seemed
        as though every rule he honestly tried to discover with them and learn
        with them was so full of exceptions and contradictions and
        qualifications and confusions that he wished he’d never come across
        the rule in the first place.

        A student would always ask how the rule would apply in a certain
        special circumstance. Phædrus would then have the choice of trying to
        fake through a made-up explanation of how it worked, or follow the
        selfless route and say what he really thought. And what he really
        thought was that *the rule was pasted on to the writing after
        the writing was all done*. It was post hoc, after the fact,
        instead of prior to the fact.

        (Robert M. Pirsig, [[http://design.caltech.edu/Misc/pirsig.html][Zen and the Art of Motorcycle Maintenance]])
    #+END_QUOTE

*** Компартментализм

    Термин из психологии. По-русски обычно переводят как "раздельное
    мышление". Типовые примеры из википедии: чудеса гуманизма в
    общественной деятельности, сочетающиеся с домашним насилием и
    жестокостью; борьба с порнографией, сочетающаяся с обширной
    домашней коллекцией порно.

    Если долго собирать цитаты, в них начинают появляться
    противоположные. Иногда один и тот же человек с течением времени
    высказывает противоположные взгляды (это нормально, он растет и
    меняется).

    Идея игры в том, что брать цитаты из разных мест и укладывать их в
    два столбика – за и против. Потом смотреть на то, как по любому
    вопросу есть две противоположных точки зрения, представленные
    вполне убедительными людьми. Может быть даже в три столбика: за,
    против и синтез – но попыток синтеза вокруг очень мало. Хотя идея
    "срединного пути" совсем не нова, и была озвучена как упоротыми
    изотериками, так и психотерапевтами.

    Я дошел до этой игры сам, но позже обнаружил, что уже есть сервис
    реализующий похожий подход – lovehate.ru. Там обитает много
    школьников, что конечно его портит.

    Играть в эту игру можно просто с самим собой, находя противоречия
    как в себе, так и в окружающем мире. Но есть и вторая цель –
    сделать какой-то аналог [[https://en.wikipedia.org/wiki/Debate#Student_debating_societies][дискуссионного клуба]]. Сбор best arguments,
    за и против какой-нибудь идеи.

    Конечная цель игры – синтез разных мнений.

    #+BEGIN_QUOTE
        Раздельное мышление — это защитный механизм,
        позволяющий человеку умещать в себе логически несовместимые
        установки. Если по каким-то причинам человек нуждается в каждой из
        своих несовместимых установок, то осознание возникающего
        противоречия начинает занимать мысли попытками это противоречие
        разрешить (зачастую с помощью рационализаций). Чтобы этого не
        происходило, человек может начать «раздельно мыслить» — не
        осознавая противоречия между ними, придерживаться всех
        несовместимых установок сразу. Со стороны это выглядит как простое
        лицемерие, но сам человек в этом случае придерживается своих
        установок вполне искренне, хотя и использует в каждом конкретном
        случае только одну из них.

        (Википедия, Мак-Вильямс)
    #+END_QUOTE

    #+BEGIN_QUOTE
        Настоящий спор, говорю тебе из лагерного опыта, производится
        как поединок. По согласию выбираем посредника – хоть Глеба
        сейчас позовем.  Берем лист бумаги, делим его отвесной чертой
        пополам. Наверху, через весь лист, пишем содержание
        спора. Затем, каждый на своей половине, предельно ясно и
        кратко, выражаем свою точку зрения на поставленный
        вопрос. Чтобы не было случайной ошибки в подборе слова –
        время на эту запись не ограничивается. [...] Пустые
        словопрения и сотрясения воздуха могут тянуться неделями. А
        спор на бумаге иногда кончается в десять минут: сразу же
        становится очевидно, что противники или говорят о совершенно
        разных вещах или ни в чем не расходятся. Когда же выявляется
        смысл продолжать спор – начинают поочередно записывать доводы
        на своих половинках листа.

        (Солженицин, "В круге первом")
    #+END_QUOTE

** События

   Я прочитал несколько книг про историю компьютеров и сетей и понял,
   к моменту прочтения последней, я уже не могу сопоставить даты,
   которые мне описывают сейчас, с датами, которые были описаны в
   предыдущих книгах. Было бы круто наложить последовательности
   событий друг на друга и показать это все на таймлайне.

   Проблема в том, что когда я слышу, что "Хоббит" был опубликован в
   1937 году, я уже давно забыл, что в том же году вышла первая
   диснеевская полнометражка. События, даты которых я слышу, для меня
   находятся в вакууме. Если их выписывать, то со временем контекста
   будет становится все больше.

   Так же это здорово прочищает мозг, потому что выясняется с какой
   легкостью я ошибаюсь на плюс-минус десять лет в интуитивной оценке,
   когда что-то произошло.

   Кое-как, но события сейчас реализованы. Их можно добавлять,
   разглядывать на таймлайне через [[http://visjs.org][vis.js]], и крепить вместе с цитатами
   к оглавлению книги.

   [[./images/timeline/timeline1.png]]

** Словарь

*** Личный словарь терминов

    Карточки для терминов, встреченных в тексте. Крепятся к
    оглавлению. Автоматически генерируют ссылки на запрос в гугл и
    википедию.

*** Словарь иностранных слов

    Например берем субтитры на английском, тупо режем их на слова и
    удаляем всякий очевидный мусор. ﻿Прикручиваем [[https://wordnet.princeton.edu/][WordNet﻿]]. Удаляем
    множественные числа, превосходные степени, глагольные формы,
    междометия, предлоги и местоимения. Считаем частотность. Находим
    самые частовстречающиеся 2000 слов ([[https://en.wikipedia.org/wiki/Basic_English]["core vocabulary"]]). Делаем
    интерфейс, в котором пользователь может отметить знает он это
    слово или не знает (там не надо думать, если сомневаешься,
    говоришь, что не знаешь). На вычитку 1000 слов у меня уходило
    меньше часа. Предположим, что средний словарный запас у
    англоговорящего 20-30k слов, у того кто учит язык – сильно
    меньше. За 10-20 часов систему можно научить всем словам, которые
    ты знаешь. По сравнению со временем обучения языку это очень мало.

    Ок, на выходе мы получили список слов. Что теперь с ним можно
    поделать?

    Во-первых, можно прогнать свежий текст через базу и найти слова,
    которых ты не знаешь. Если прикрутить [[https://github.com/louismullie/treat][treat]], то еще и с частью
    речи. Теперь можно автоматом генерить из них карточки для
    запоминания, в которых будет учитываться часть речи ("мне
    встречалось это слово как глагол, а тут оно как существительное"),
    автоматически добавляться пример в котором слово попалось и будет
    стоять ссылка на конретный источник, откуда слово взялось. Это
    очень круто, потому что руками делать карточки вымораживает. Из
    упоротых идей: можно скриншот делать из видео, где это слово
    показыватеся.

    Во-вторых, можно оценивать лексическую сложность текста до
    прочтения.

    В-третьих, можно понимать какие слова учить первыми, потому что
    они чаще встречаются.

    На картинке синяя часть полоски – это базовая лексика, красная –
    слова, которые повторяются два и больше раз, и желтая – слова,
    которые встречаются в сериале один раз.

    [[./images/words/words.png]]

** Импорт данных из веб-сервисов

   О плохом сервисе никто не знает, хороший закроется через 10
   лет. Плохой сервис не отдает данные пользователям, хороший имеет
   выгрузку данных и api. Но что с ними делать, если он все равно
   закрылся? Интерфейс пропал. Что делать с несколькими
   экспортированными наборами данных, если хочется единую ленту?

   Примеры веб-сервисов, которые пытались делать единую ленту: Singly,
   Locker, Memolane, FriendFeed. В настоящий момент все закрыты.

   Помимо единой ленты есть еще проблема единых метаданных. Теги из
   разных сервисов надо приводить к одному знаменателю.

* Поиск подхода к реализации

  Самое вменяемое решение, которое я вижу – это [[https://en.wikipedia.org/wiki/Resource_Description_Framework][RDF]].

** Декомпозиция

*** Блог

   Представим себе блог, где каждый пост не является монолитом, а
   собирается из кусочков-атомов. Каждый атом имеет уникальный
   идентификатор, хранится отдельно и имеет свой набор
   атрибутов. Каждый параграф, картинка, видео-ролик в посте – это
   атом. Структура поста задается списком из уникальных идентификаторов
   каждого атома, каждый из которых трансклюдится в пост. На каждый
   параграф в посте можно сослаться, навесить атрибуты и добавить
   комментарии.

   Структура каждого комментария к посту повторяет его структуру. К
   этому добавляется древовидный или линейный контейнер, который хранит
   порядок комментариев.

   Посты организуются в хронологическое дерево. Это может быть
   стандартная схема год/месяц/день или какая-нибудь другая, например,
   год/неделя/день. Деревьев может быть несколько, выбор определяется
   удобством.

   Какие элементы структуры имеем в результате?

   - атомы с атрибутами
   - линейный список для объединения атомов в посты
   - комментарии, каждый из которых повторяет структуру поста
   - дерево для комментариев
   - посты организуются в хронологическое дерево

   Теперь отрезаем лишние сущности.

   Между атомом и постом нет никакой разницы. Оба имеют уникальный
   идентификатор и набор атрибутов. Разница только в том, что у поста
   есть сложный атрибут, который хранит список входящих в него
   атомов. Сущность, обладающую уникальным идентификатором, на которую
   можно навесить атрибуты я дальше буду называть ресурсом.

   Между деревом и линейным списком нет никакой разницы, поскольку
   дерево – это просто список списков. Дерево комментариев – это список
   списков, листьями которого являются ресурсы, содержащие комментарии.

   Теперь у нас есть два вида ресурсов: посты и комментарии. На самом
   деле, даже больше, потому что атомы тоже различаются – текст,
   картинка, видео. Поскольку у нас есть несколько типов ресурсов,
   логично ввести понятие тип ресурса. Определение ресурса расширяется
   до сущности, у которой есть уникальный идентификатор, атрибуты и
   тип. Тип – это такой же атрибут, как и дата создания, заголовок или
   любая другая мета-информация. Отличает его только то, что он
   является обязательным, поскольку без него мы не будем знать, как
   обрабатывать ресурс. Допустим, мы генерируем на основе нашей
   структуры html. Чтобы отобразить текстовый атом, надо преобразовать
   содержащуюся в нем разметку (например markdown) в html, обернуть
   это в div и отдать браузеру. Чтобы показать картинку, надо обернуть
   ее в тег img и отдать браузеру. Разница в обработке закрепляется в
   виде типа.

   Атрибуты — это, строго говоря, тоже ресурсы, а линейные списки
   создаются с помощью цепочек ресурсов, ссылающихся друг на друга. Так
   что кроме ресурсов ничего особо и не остается, но атрибуты и
   линейные списки мы выкидывать пока не будем, а то говорить не о чем
   будет.

   Итак, у нас остались:

   - ресурсы
   - атрибуты
   - линейные списки

   Переводим в термины rdf:

   - ресурс по-прежнему остается ресурсом (rdf:Resource)
   - атрибуты в терминологии rdf называются rdf:property
   - атрибут «тип ресурса» – это rdf:type
   - ресурсы, описывающие атрибуты, имеют rdf:type равным rdf:Property

   Схема получается довольно заманчивая, потому что в базе данных все
   поместится в две таблицы: одна для графа и одна для сопоставления
   идентификаторов атомов и все было бы хорошо, если бы речь шла про
   однопользовательскую систему, например, если бы мы говорили про
   гибкую структуру для бекапа различных блогов. Но у блога есть
   комментарии и пользователей много. Нужно разграничение
   доступа. Красивая схема «все в двух таблицах» разваливается. Права —
   зло, про них придется думать отдельно.

   Чтобы два раза не вставать, сразу скажу, что в смысле бекапа блог не
   сильно отличается от твиттера, френдфида, фликра и многого
   другого. Все упирается в модель безопастности.

*** Оценка количества триплетов при импорте книги

    На примере книги [[http://www.learningsparql.com/]["Learning SPARQL"]].

    Поиск блочных элементов:

    : cat OEBPS/*html > all
    : grep -cP '<img|<ol|<li[>\s]|<ul[>\s]|<p[>\s]|<pre[>\s]|<h\d[>\s]|<dd|<dt|<table|<tr|<td' all
    : => 2363 <1>

    Количество заголовков в оглавлении:

    : grep -cP '<a' bk01-toc.html
    : => 268

    Получается в среднем около 8 блочных элементов на элемент
    заголовка. Предположим, что большинство элементов прикреплены к
    заголовкам третьего уровня. (Уровень заголовка считается от единицы.)

    hasPart / isPartOf. Формула: ~2 * n * (d + 1)~ Каждый блочный элемент
    принадлежит своему заголовку и всем его родительским.

    : 2 * 2363 * (3 + 1) = 18904 <2>

    Теперь у нас есть количество элементов и есть связи. Надо какие-то
    индексы, чтобы сортировать части внутри заголовка. Придется
    использовать упоротую систему нумерации из rdf, где для описания
    связи двух элементов нужно три триплета.

    : (2363-1) * 3 = 7086 <3>

    С учетом того, что информация про язык, авторов и так далее не
    подвергается инференсингу, то в сумме получается:

    : 2363 + 18904 + 7086 = 28353

    30k триплетов на одну книгу. На 1k книг – 30 000 000 триплетов.

** Базовые определения

*** Ресурс

    Отдельная сущность, адресуемая уникальным идентификатором. Роль
    идентификатора выполняет URI.

    Имеет множество атрибутов в формате ключ=значение.

    Имеет множество представлений.

    Ресурс имеет класс, который определяет его базовый логический
    тип. Класс определяет какие атрибуты можно вешать на этот ресурс и
    с помощью каких представлений его рисовать.

    Идентификатор позволяет выцепить из источника данных настоящий
    контент, соответствующий ресурсу. Это так называемый dereferencing.

    Контент есть только у неделимых ресурсов, то есть на самом деле не
    у всех. Контент есть у ресурса, являющегося параграфом текста,
    картинкой, аудио-файлом, видео-файлом. Для ресурсов, у которых нет
    контента, устанавливается некий пустой адаптер.

*** Представление

    У ресурса есть класс. Классу соответствует множество представлений,
    из которого выбирается нужное. Представление – это шаблон, который
    получает на входе ресурс, достает из него хеш с атрибутами, с
    помощью адаптера получает контент и рисует из всего этого html.

    У одного ресурса есть множество представлений.

    Три стандартных, которые показывают ресурс вне зависимости от того
    есть у него класс или нет:

    1) ~default~ – показывает атрибуты и контент. Атрибуты содержащие
       ссылки на другие ресурсы показываются просто ссылками и никак не
       отображаются.
    2) ~inline~ – показывает только контент. Для параграфа это текст в
       теге ~<p>~, для картинки тег ~<img>~ и так далее.
    2) ~link~ – показывает только ссылку на ресурс.

    Расширенные, опирающиеся на класс:

    1) ~classed-link~ – отображает иконку рядом со ссылкой в зависимости
       от типа ресурса.
    2) ~card~ – показывает некоторую компактную summary по ресурсу и
       ссылку на полную версию. Например для книги это может быть
       обложка, под которой написано полное название и год
       издания. Карточки используются при отображении "плитки" из
       ресурсов.
    3) ~classed-link-with-card~ – ~classed-link~ у которой при навении
       мышки на ссылку появляется карточка во всплывающем окне.

*** Атрибут

    Атрибут тоже ресурс. На него тоже можно навешивать атрибуты.

    Адаптер для него HTTP, потому что так сложилось.

    Формат атрибута ~<attribute>=<value>~. UUID ресурса плюс ключ и значение
    образовывают триплет.

*** Адаптер

    URI состоит из NID и NSS.

    NID – namespace id. Позволяет выбрать адаптер для совершения с ресурсом базовых
    действий.

    NSS – namespace spicific string. Позволяет однозначно ссылаться на
    ресурс внутри определенного namespace.

    Основные действия, которые должен поддерживать ресурс:

    - создание
    - чтение
    - редактирование
    - удаление

    Действия над метаданными внутри ресурса:

    - добавить единицу метаданных в формате ключ=значение
    - вернуть значение по определенному ключу
    - считать все метаданные и вернуть хеш
    - установить значение по определенному ключу
    - удалить единицу метаданных по ключу

    Некоторые ресурсы могут не поддерживать метаданные (plain text) или
    быть недоступными для удаления/редактирование (страница в
    интернете). В этом случае адаптер просто не поддерживает эти
    операции.

* Как это все может выглядеть на практике

  RDF – это идея, что данные хранятся в графе. Хранить этот граф и
  управлять им можно по-разному.

** Реляционный подход

   Лучше всего про реляционный подход написал какой-то чувак с [[https://news.ycombinator.com/item?id=10326764][HN]]:

   #+BEGIN_QUOTE
       Having a completely abstracted database with one big
       table called "things" and another big table called "relationships"
       seems really attractive before you actually do it. Then it starts
       to suck.
   #+END_QUOTE

   Все хранится в трех таблицах: =Resources=, =Properties=, =Trees=.

   =Trees= – это оптимизация, которая позволяет хранить деревья,
   упорядоченные и не упорядоченные списки, не прибегая к упоротому
   способу ~rdf:next~.

   В таблице =Resources= включен single-table inheritance, который
   выгружает ресурсы в соответствующие ruby-классы.

   Валидации делаются засчет того, что у ресурсов типа =Property= в
   классах есть методы в духе =domain= и =range=, которые возвращают
   множества того, что можно крепить к свойству слева и справа
   соответственно.

   Инферинг делается в духе:

   : after_create :add_inverse_property

   У классов нет множественного наследования. Мне оно строго говоря и
   не нужно, но реализовывать проще, если принять это
   ограничение. Правда придется разруливать два триплета с которых
   вообще начинается вся семантика. Потом все нормально.

*** Конспект

    Сначала у нас есть один ресурс – книга. У него есть атрибут =content=
    в котором лежит ссылка на дерево.

    Ссылка на дерево – это указатель на анонимный корневой элемент
    дерева, к которому крепятся его элементы. У элемента дерева, помимо
    информации о вложенности есть только одна полезная нагрузка –
    ссылка на ресурс.

    Мы делаем первый запрос и получаем из ресурса класса ~Book~ ресурс
    класса ~Outline~.

    Мы делаем второй запрос и получаем свойство ~content~ ресурса класса
    ~Outline~. В нем хранится ссылка на дерево.

    Мы делаем третий запрос и получаем упорядоченный массив
    элементов дерева, потому что nested set. Ресурсы крепятся к
    элементам дерева с помощью ~includes~. Для этого нужен один ~join~.
    На выходе получаем массив элементов дерева, с уже загруженными из
    базы элементами типа ~Paragraph~, ~Section~ или ~List~.

*** Цитаты, разложенные по главам

    У цитаты есть функциональное свойство источник. Функциональное в
    том смысле, что оно у него может быть только одно, потому что у
    цитаты есть только один источник.

    Цитата крепится свойством ~source~ к элементу оглавления класса
    ~Section~. Оглавление в книге одно на всех. К нему крепятся и
    конспекты, и цитаты, и контент. Это означает, что элемент
    оглавления должен иметь свой тип и свои свойства, к которым
    крепятся соответствующие деревья.

    Допустим он имеет тип ~Section~. У ~Section~ есть четыре атрибута:
    ~dc:title~, ~my:content~, ~my:outlite~, ~my:quotes~.

    Первый запрос: взять у книги атрибут ~оглавление~ и достать оттуда
    ссылку на анонимный элемент дерева, который хранит все элементы
    оглавления класса ~Section~.

    : resource[toc] = tree_id

    Второй запрос: прийти в таблицу деревья и вытащить оттуда всех
    детей этого анонимного элемента, сделав на них ~inludes~, что дает
    нам все ресурсы описывающие главы. Это первый ~join~.

    : tocs = Tree.find(tree_id).descendants.includes(r)

    Третий запрос: из каждого ресурса типа ~Section~ надо достать
    свойство ~quotes~, которое ссылается на анонимный элемент дерева,
    который хранит список элементов класса ~Quote~, который нам и нужен.

** Обычный реляционный подход + наведенная семантика

   Объекты каждого класса хранятся в отдельной таблице, связи между
   ними во внешних ключах. Связи лежат в коде. Новый класс – новый
   скаффолд. Ограничения разползаются в валидации и колбеки.

   На сервере стоит вордпресс, редмайн и медиавики. Делается точка
   доступа ~sparql~, которая маппит их таблицы в rdf и предоставляет
   унифицированный доступ. На основе этой точки доступа рисуется
   интерфейс.

   Основная проблема этого подхода в невозможности импорта данных из
   какого-то источника без изменения схемы хранения данных. Если схему
   не менять, то при импорте либо часть данных потеряется, либо
   придется менять их семантику. Например у нас есть хранилище,
   заточенное под wordress, а импортировать туда надо записи из
   livejournal, и поле "current mood" приходится класть прямо в текст
   записи, потому что мы не можем его добавить не программируя.

** Семантика

   [[https://en.wikipedia.org/wiki/Triplestore][Триплстор]], [[https://en.wikipedia.org/wiki/Semantic_reasoner][ризонер]], запросы на [[https://en.wikipedia.org/wiki/SPARQL][SPARQL]]. Интерфейс на
   рельсах. Моделей нет. Контроллер по сути один –
   ~ResourcesController~. В основном надо рисовать партиалы для
   отрисовки ресурсов конретного класса с указанной детализаций и
   связанными ресурсами.

*** OpenLink Virtuoso

    http://virtuoso.openlinksw.com/

*** Stardog

    https://www.stardog.com

    Платная.

    #+BEGIN_QUOTE
        It supports both semantic graphs, via RDF, SPARQL, and OWL, as
        well as property graphs via Apache TinkerPop and Gremlin–it's
        the *only graph database that supports both models over the same
        database, simultaneously*.

        – [[http://tinkerpop.apache.org/providers.html][Tinkertop doc]] / [[https://www.stardog.com/docs/#_property][Stardog doc]]
    #+END_QUOTE

    #+BEGIN_QUOTE
        Stardog supports integrity constraint validation as a data
        quality mechanism via *closed world* reasoning.

        – [[https://www.stardog.com/docs/#_validating_constraints][Stardog doc]]
    #+END_QUOTE

*** AllegroGraph

    http://franz.com/

    Выглядит вполне живым. Копирайт на сайте обновляется, есть всякие
    видео и список событий. Есть community версия и платная. Внезапно
    есть биндинги для Common Lisp и курсы по изучению Common Lisp.

** Графовая база данных

   Если конкретнее, то [[https://neo4j.com][neo4j]]. Про графовые базы
   пишут, что если цепочки связей между ресурсами больше двух, то
   можно использовать, а если нет, тогда postgres. То есть
   хранить там все нет смысла.

   Использует собственный язык запросов [[https://neo4j.com/docs/developer-manual/current/cypher/][Cypher]]. Говорят, что
   поддерживает SPARQL.

   Подозрение вызывает то, что связи не являются узлами как в RDF. На
   них можно навешивать атрибуты, но это каждый раз происходит
   локально для каждой созданной связи. То есть метаинформацию кто и
   когда добавил связь оставить можно, но нельзя сказать, что эта
   связь соединяет только определенные узлы. Эта информация уходит в
   логику приложения.

   С другой стороны это радикально упрощает provenance. Нет этой
   упоротой rdf-схемы, где для описания одной связи надо использовать
   4+n триплетов, (n – количество триплетов с мета-информацией, 4 –
   statement + subject + predicate + object). Как оно устроено внутри,
   мне не интересно, главное что думать про это не надо будет.

   Очень привлекают примеры с быстрой загрузкой данных из WordNet и
   dbpedia.

   Определенно хорошо применять для:
   - связей между цитатами
   - связей между параграфами

   Книга O'Reilly "Graph Databases" – это введение в neo4j.

   Обертка для ruby: [[https://github.com/neo4jrb/neo4j][neo4jrb]] ([[https://neo4jrb.readthedocs.io/en/7.1.x/][docs]] / [[https://www.youtube.com/watch?v=bDjbqRL9HcM][блог на neo4jrb за 10 минут]])

* История

** (1945) Vannevar Bush — As We May Think

   The Atlantic: [[http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/][As We May Think]]

   Wikipedia: [[https://en.wikipedia.org/wiki/Memex][Memex]]

** (1967) Andries van Dam, Ted Nelson — Hypertext Editing System

   Wiki: [[https://en.wikipedia.org/wiki/Hypertext_Editing_System][HES]]

** (1968) Douglas Engelbart — oN-Line System

   Wiki: [[https://en.wikipedia.org/wiki/The_Mother_of_All_Demos][The Mother of All Demos]] / [[https://en.wikipedia.org/wiki/NLS_(computer_system)][oN-Line System]]

   Видео: http://www.1968demo.org/

** (1968) Andries van Dam — File Retrieval and Editing System

   Wiki: [[https://en.wikipedia.org/wiki/Hypertext_Editing_System][FRESS]]

   #+BEGIN_SRC event
        label:       FRESS (File Retrieval and Editing System)
        description: Andries van Dam
        category:    infoorg
        start_date:  1968
        link:        https://en.wikipedia.org/wiki/Hypertext_Editing_System
        location:    USA
   #+END_SRC

** (1985) Intermedia

   Wiki: [[https://en.wikipedia.org/wiki/Intermedia_(hypertext)][Intermedia]]

   #+BEGIN_QUOTE
       In 1983 Andries van Dam, William S. Shipp and Norman Meyrowitz founded
       the Institute for Research in Information and Scholarship (IRIS) at Brown.
       Their most notable project was Intermedia, a networked, shared, multiuser
       hypermedia system explicitly designed for use within university research and
       teaching environments. Intermedia was started in 1985 and sponsored by the
       Annenberg/CPB project and IBM (Meyrowitz 1986, 196).
   #+END_QUOTE

** (1991) Gifford — Semantic file systems

   Старая заметка про Гиффорда:

   #+BEGIN_QUOTE
       Подход, описанный Гиффордом, можно наглядно продемонстрировать
       на примере del.icio.us. Факт того, что он писал это еще в 1991
       году, убивает на фиг. Но. Главный недостаток этого подхода
       заключается в том, что когда множества полей (fields) и их
       значений (values) выростет, системой будет невозможно
       пользоваться. Это видно и на примере делишеса. Никто не
       пользуется инкрементным поиском. Это прикольно, но медленно и
       нафиг никому не сдалось. Проблема инкрементного поиска в том,
       что вылезает слишком много не нужных параметров.

       Сохраненные запросы имеют то преимущество перед подходом Гиффорда, что
       они заранее отсеивают ненужные параметры поиска. Дело не в том, что
       дерево – это плохо. Дело в том, что одно дерево это плохо. Деревьев
       должно быть много. В файловую систему из можно интегрировать с помощью
       виртуальных файловых систем.
   #+END_QUOTE

** (1993) LDAP

   LDAP интересен своей способностью строить классицификаторы. Там
   есть классы, наследование, всякие прочие штуки. Для 1993 года
   неплохо.

   Wiki: [[https://en.wikipedia.org/wiki/Lightweight_Directory_Access_Protocol][LDAP]]

   [[http://www.zytrax.com/books/ldap/][LDAP for Rocket Scientists]]

** (1996) Eric Freeman and David Gelertner — Lifestreams

   Wiki: [[https://en.wikipedia.org/wiki/Lifestreaming][Lifestreaming]]

** (1999) Presto

   Paul Dourish, W. Keith Edwards, Anthony LaMarca and Michael
   Salisbury. Xerox Palo Alto Research Center.

   [[http://www.dourish.com/publications/1999/tochi-presto.pdf][Presto: An Experimental Architecture for Fluid Interactive Document Spaces]]

** (2000) id3v2.4

   Informal standard на теги для mp3 файлов. Не смотря на то, что
   структура метаданных хорошо прописана, по большому счету ее никто
   не использует.

   Проблема метаданных для музыки – обширная тема, надо ее чуть позже
   раскрыть.

   http://id3.org/id3v2.4.0-frames

** (2000) MusicBrainz

   Отлично прописанная онтология для музыки. Last.fm забирает данные
   именно отсюда.

   https://musicbrainz.org/

** (2001) Eric Kim — Purple

   Подход к решению проблемы идентификации частей документа. Добавляет
   для блочных элементов в html якоря со ссылками. Реализация идеи Нельсона.

   https://en.wikipedia.org/wiki/Purple_Numbers

** (2001) Tim Berners-Lee — Semantic Web

** (2001) Tinderbox

   По сути – mindmap. Есть заметки, у них есть классы (прототипы на
   местном сленге) и аттрибуты. Из классов можно делать иерархии.

   Есть несколько способов отображения заметок: mindmap (с
   возможностью заныривания в поддерево), timeline, outline, карта. В
   смысле отображение Tinderbox хорош, хотя он упускает один важный
   способ отображения – лента.

   Между заметками можно делать связи. Связи можно делать между любыми
   заметками, даже если они находятся на разных уровнях иерархии. Есть
   инспектор, который показывает все входящие и исходящие связи для
   конкретной заметки.

   Tinderbox не является редактором гипертекста (и тем более блочным
   редактором), связи у него существуют только на уровне
   заметок. Метаданные тоже можно навешивать на уровне заметок. Текст
   по-прежнему лежит одним куском.

   Книга: [[http://www.markbernstein.org/][Mark Bernstein]] – [[http://www.eastgate.com/Tinderbox/TinderboxWay.html][The Tinderbox Way]]

   Сайт разработчика: [[http://www.markbernstein.org/][Mark Bernstein]]

   Wiki: [[https://en.wikipedia.org/wiki/Tinderbox_%28application_software%29][Tinderbox]]

** (2003) Joshua Schachter — Del.icio.us

   Старая заметка про [[https://delicious.com][delicious]]:

   #+BEGIN_QUOTE
       Про отношения с делишесом. Плохие у меня с делишесом
       отношения. Естественный подход мне не нравится. Точнее он у
       меня изначально вызвал какое-то непонимание. Поэтому изначально
       я пользовался противоестественным способом. Пытался добавлять
       избытычные метаданные. Сделал подобие онтологии. Но проблема
       этого подхода в том, что дальше с данными сделать ничего
       нельзя. Язык запросов лучше даже на френдфиде.

       Есть другая сторона. Почему фрф лучше для показывания
       ссылок. Сохранение ссылки очень мало кто сопровождает тем почему
       эта ссылка привлекла внимание. Никто не пишет эту самую
       пресловутую тысячу знаков. Это долго и никому не
       инетересно. Сохранение ссылки – это тоже самое рассказывание
       истории. Потому что без истории ссылки никому не нужна. Этих
       ссылок вокруг слишком много, чтобы во все тыкать и самому
       разбираться что там к чему. Социальность делишеса проявляется
       только в одном случае – когда люди начинают искать популярные
       ссылки по какому-то тегу.

       Компенсировать отсутствие обсуждения заправлением делишеса во
       френдфид тоже плохо. Потому что если исходить из того, что это все
       ссылки "на потом", то соотношение сигнал/шум становится слишком
       низким. Каждый сохраняет в день по несколько ссылок умножить на
       количество френдов – получается жуткий мусор. Поэтому ссылки нужно
       обсуждать там, где они лежат.

       Одно время я очень перся от делишеса, но сейчас это прошло. Тогда
       мне хотелось, чтобы так можно было работать с файлами на харде. Но
       если из метаданных нельзя ничего выжать, то на фиг они нужны?

       У делишеса есть проблема интерфейса – сохранять слишком долго. В
       результате на смену ему пришел Read It Later. Пост сохраняется
       одним нажатием галочки. Получается обычный линейный список. То,
       что прошло испытание временем переносится в делишес. Или про это
       рассказывается история во френфиде. Лишнее удаляется одним
       кликом. То что там нет тегов – это отдельная тема. Мне кажется,
       что ключевые слова можно вытаскивать из текста
       автоматом. Используя API того же делишеса или гугла. Или тупо
       смотреть по частоте.

       Получается, что делишес – это медленные коммуникации. Медленные
       именно из-за интерфейса, а не по сути. Из этого вытекает очевидное
       в принципе заключение, что пропускная способность интерфейса
       определяет суть сервиса. Если сделать медленный интерфейс для
       чата, то это будет уже форум. Условно говоря. Если сделать быстрый
       интерфейс для форума, то получится френдфид. Опять же очень
       условно.
   #+END_QUOTE

** (2003) Carsten Dominik — Org-mode

   Outliner для emacs. Выяснилось, что пока нет хорошего инструмента,
   которому можно доверять, вполне можно жить с помощью текстовых
   файлов и git.

   http://orgmode.org/

** 2006 Calibre

** (2004) W3C — RDF / RDFS / OWL

** (2007) DBpedia

   Вытаскивает структурированные данные из википедии, конвертит их в
   RDF, позволяет делать запросы на SPARQL.

   Wiki: [[https://en.wikipedia.org/wiki/DBpedia][DBpedia]]

** (2007) Scrivener

   Инструмент для написания текстов. Есть текстовый редактор и
   контроль версий. Есть хранилище связанных файлов и их отображение в
   виде доски. Какие-то инструменты для рефакторинга в духе
   "переименовать персонажа".

   Надо еще в нем покопаться, но пока ощущение что в целом он про текст
   как проект.

   http://www.literatureandlatte.com/scrivener.html


** (2008) Evernote

   Подкаст с Пачиковым: [[http://runetologia.podfm.ru/96/][Рунетология 45]]

   Wiki: [[https://en.wikipedia.org/wiki/Evernote][Evernote]]

** (2009) Fluidinfo

   У них очень прикольный [[http://blogs.fluidinfo.com/][блог]], если читать его с начала, а не с конца.

   http://fluidinfo.com

** (2013) Ginko

   Хороший. Умеет делать презентации и возвращать текст в виде
   json. Интересен в первую очередь интерфейсом.

   https://gingkoapp.com

   Reference-mode в читалке. Решение проблемы идентификации для
   электронных книг.

   https://calibre-ebook.com/

** Smallest Federated Wiki

   Создатель первой вики, [[https://en.wikipedia.org/wiki/Ward_Cunningham][Ward Cunningham]], делает федеративную
   вики. Страницы можно форкать и поддерживать локально свою версию.

   http://fed.wiki.org

** Chandler

   Wiki: [[https://en.wikipedia.org/wiki/Chandler_%28software%29][Chandler]]

** CommonTag

   Теги на основе заголовков статей в википедии. Позволяют получить
   для тега хорошо прописанную семантику, в том числе на разных
   языках. Какая-то инкарнация этой идеи вроде используется в facebook
   для отмечания интересов пользователя.

   http://microformats.org/wiki/CommonTag

** Friendfeed

   Помимо всего прочего умел собирать данных из разных источников в
   одну ленту.

** Locker

   Метасервис по собиранию данных из разных веб-сервисов в единую
   ленту.

** Singly

   Метасервис по собиранию данных из разных веб-сервисов в единую
   ленту. Singly ориентирован не только на собирание, но и на
   предоставление к собранному API для различных манипуляций и
   визуализации.

   #+BEGIN_QUOTE
      Singly was founded by Jeremie Miller, creator of XMPP, Jason Cavnar
      and Simon Murtha-Smith. Matt Zimmerman, former CTO of Ubuntu,
      joined Singly and was the CTO.
   #+END_QUOTE

   2013-08-22 – поглощен компанией [[http://appcelerator.com/][appcelerator]].

** NEPOMUK

   https://en.wikipedia.org/wiki/NEPOMUK_%28framework%29

** TiddlyWiki

   http://tiddlywiki.com/

* Ссылки

   http://infotoday.com/ – новости

   http://booksblog.infotoday.com/ – книги

   Каталог статей на сайте Брета Виктора: Engelbart, Bush, Alan Key и
   другие - http://worrydream.com/refs/.

** Учебные заведения

   [[http://www.ischool.berkeley.edu/][UC Berkeley School of Information]]
   - [[https://bcourses.berkeley.edu/courses/1247347/assignments/syllabus][INFO202: Information Organization and Retrieval (Fall 2014)]]

   [[https://ischool.uw.edu/][University of Washington Information School]]
   - [[http://kftf.ischool.washington.edu/][Keeping Found Things Found]]

** Термины

   - [[https://en.wikipedia.org/wiki/Personal_information_manager][Personal information manager]]
   - [[https://en.wikipedia.org/wiki/Semantic_Web][Semantic Web]]
   - [[https://en.wikipedia.org/wiki/Personal_knowledge_base][Personal knowledge base]]
   - [[https://en.wikipedia.org/wiki/Information_science][Information science]]
   - [[https://en.wikipedia.org/wiki/Faceted_classification][Faceted classification]]
   - [[https://en.wikipedia.org/wiki/Metadata][Metadata]]
   - [[https://en.wikipedia.org/wiki/Entity%E2%80%93attribute%E2%80%93value_model][Entity–attribute–value model]]
   - [[https://en.wikipedia.org/wiki/Adaptive_hypermedia][Adaptive hypermedia]]
   - [[https://en.wikipedia.org/wiki/Hypertext][Hypertext]]
   - [[https://en.wikipedia.org/wiki/Semantic_desktop][Semantic desktop]]
   - [[https://en.wikipedia.org/wiki/Parallel_text][Parallel text]]
   - [[https://en.wikipedia.org/wiki/Transclusion][Transclusion]]
   - [[https://en.wikipedia.org/wiki/Graph_database][Graph database]]
   - [[https://en.wikipedia.org/wiki/Universally_unique_identifier][Universally unique identifier (UUID)]]
   - [[https://en.wikipedia.org/wiki/Uniform_Resource_Identifier][URI]] / [[https://en.wikipedia.org/wiki/Uniform_Resource_Locator][URL]] / [[https://en.wikipedia.org/wiki/Uniform_Resource_Name][URN]]
   - [[https://en.wikipedia.org/wiki/Dublin_Core][Dublin Core]]

** Люди

   - [[https://en.wikipedia.org/wiki/Douglas_Engelbart][Douglas Engelbart]]
   - [[https://en.wikipedia.org/wiki/Vannevar_Bush][Vannevar Bush]]
   - [[https://en.wikipedia.org/wiki/Andries_van_Dam][Andries van Dam]]
   - [[https://en.wikipedia.org/wiki/Ted_Nelson][Ted Nelson]]

** Книги

   История:
   - [[http://www.anthempress.com/memory-machines][Memory Machines: The Evolution of Hypertext]] (Anthem Press)

   Техническое:
   - A Semantic Web Primer (MIT Press)
   - Semantic Web for the Working Ontologist (Morgan-Kaufman)
   - Learning SPARQL (O'Reilly)
   - Graph Databases (O'Reilly)

   Методологическое:
   - Keeping Found Things Found (Morgan-Kaufman)
   - The Discipline of Organizing (MIT Press)

   Художественное:
   - Игра в бисер (Герман Гессе)

** Ассоциации

   * [[https://www.asist.org/][Association for Information Science and Technology]]

** urbansheep

*** Pinboard

    - [[https://pinboard.in/u:urbansheep/t:km/][KM]] / [[https://pinboard.in/u:urbansheep/t:knowledgemanagement/][knowledgemanagement]]
    - [[https://pinboard.in/u:urbansheep/t:infoorg/][infoorg]]
    - [[https://pinboard.in/u:urbansheep/t:hypertext/][hypertext]]
    - [[https://pinboard.in/u:urbansheep/t:semanticweb/][semanticweb]]
    - [[https://pinboard.in/u:urbansheep/t:classification/][classification]]
    - [[https://pinboard.in/u:urbansheep/t:metadata/][metadata]]

*** FriendFeed

    - [[http://urbansheep.com/friendfeed/urbansheep/lists/hashtags/infoorg.html][инфоорг]]
    - [[http://urbansheep.com/friendfeed/urbansheep/lists/hashtags/svoy_nebolshoy_internet.html][свой небольшой интернет]]
    - [[http://urbansheep.com/friendfeed/urbansheep/lists/hashtags/tsifrovaya_istoriya.html][цифровая история]]
    - [[http://urbansheep.com/friendfeed/urbansheep/lists/hashtags/arhivisty.html][архивисты]]

*** LiveJournal

    - [[https://urbansheep.livejournal.com/tag/info organization][info organization]]
    - [[https://urbansheep.livejornal.com/tag/classification][classification]]
    - [[https://urbansheep.livejournal.com/tag/memory_management][memory management]]
    - [[https://urbansheep.livejournal.com/tag/knowledge_management][knowledge management]]
    - [[https://urbansheep.livejornal.com/tag/hypertext][hypertext]]


** Конференции

   * [[https://archive.org/details/PDA2015][Personal Digital Archiving Conference]]
